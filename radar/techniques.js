const content = [
  {
    name: "Contract Testing",
    ring: "Assess",
    quadrant: "Techniques",
    isNew: "FALSE",
    status: "Moved In",
    description: `
      <h4>Description</h4>
      <p>
        Contract testing is a methodology for ensuring that two separate systems (such as two microservices) are compatible and can communicate with one other.
        It captures the interactions that are exchanged between each service, storing them in a contract, which then can be used to verify that both parties adhere to it.
        Contract testing goes beyond schema testing, requiring both parties to come to a consensus on the allowed set of interactions and allowing for evolution over time.
      </p>
      <br/>
      <p>
        What sets this form of testing apart from other approaches that aim to achieve the same thing is that each system can be tested independently from the other and that
        the contract is generated by the code itself, meaning the contract is always kept up to date.
      </p>
      <br/>
      <p>One of the tools mostly used for contract testing is Pactflow</p>
      <br/>
      <h4>Pros:</h4>
      <ul>
        <li><strong>Fast</strong>&nbsp;Contact tests run fast and are not relient on other systems</li>
        <li><strong>Easy to maintain</strong>&nbsp;</li>
      </ul>
      <br/>
      <h4>Cons:</h4>
      <li><strong>Sharing</strong>&nbsp;Contracts have to be shared between producer and consumer</li>
      <br/>
      <h4>Conclusion</h4>
      <p>We think contract testing can be used to complement unit and integration tests. It can give early warnings if or when systems won't be able to communicate with eachother.</p>
    `
  },
  {
    name: "BDD",
    ring: "Hold",
    quadrant: "Techniques",
    isNew: "FALSE",
    status: "No Change",
    description: `
      <h4>Description</h4>
      <p>
        <strong>BDD</strong>, Behavior Driven Development is a technique mostly used to enable easier collaboration between developer, tester and (business) users.
        Stories (features) are written in a human readable form, focussed on behavior of the system. Usually, these files are written in Gherkin, a special syntax used in
        BDD to allow tools like Cucumber and SpecFlow to automatically validate the “behaviors” encoded for a process.<br />
        Every step in the stories or feature files are then translated to actions in the application under test via Page Object, Steps and Actions.
      </p>
      <p>
        Examples of popular BDD frameworks are
        <ul>
          <li>Cucumber</li>
          <li>Behave / JBehave</li>
          <li>Specflow</li>
        </ul>
      </p>
      <br/>
      <h4>Pros:</h4>
      <ul><li><strong>pro</strong> description</li></ul>
      <br/>
      <h4>Cons:</h4>
      <ul><li><strong>con</strong> description</li></ul>
      <br/>
      <h4>Conclusion</h4>
      <p>
        Although this technique is widely used we don't recommend to use this technique anymore. Maintainability and ease of debugging / reporting are reasons to use other techniques and tools
        when testing you application. We notice that collaboration is not really happening at a lot of companies we work for. Acceptance criteria are mostly written by business stakeholder together
        with the dev team, but writing complete stories are not written by them. And this will then be the task of, for instance, the tester, negating the supposed pro of using this technique.
      </p>
    `
  },
  {
    name: "TDD",
    ring: "Assess",
    quadrant: "Techniques",
    isNew: "FALSE",
    status: "No Change",
    description: `
      <h4>Description</h4>
      <p>
        Description
      </p>
      <br/>
      <h4>Pros:</h4>
      <ul><li><strong>pro</strong> description</li></ul>
      <br/>
      <h4>Cons:</h4>
      <ul><li><strong>con</strong> description</li></ul>
      <br/>
      <h4>Conclusion</h4>
      <p>This is the conclusion</p>
    `
  },
  {
    name: "Visual Regression Testing",
    ring: "Hold",
    quadrant: "Techniques",
    isNew: "FALSE",
    status: "No Change",
    description: `
      <h4>Description</h4>
      <p>
        By using a visual regression testing tool you can detect GUI visual issues which cannot be found easily by running other automated tests,
        or only when doing manual tests repeatedly.<br/>
        Visual regression testing is not usable in every situation, but could be a benefit for some. When you use storybook for instance, it would be
        very easy to also use the chromatic plugin and easily check you components visually.
      </p>
      <p>
        There are also a number of tools which implement visual testing on their own, each with their own benefits. But the major drawback still is that
        your performing a pixel by pixel comparison of a baseline with a current snapshot, which can easily result in flaky tests or missed regression because
        your threshold is too high.
      </p>
      <p>
        Is there perhaps a future in AI driven visual regression testing. That is also a subject we as a group would like to investigate. So maybe in the future
        we will see more development in this technique.
      </p>
      <br/>
      <p>
        Examples of popular visual testing tools are
        <ul>
          <li>Chromatic</li>
          <li>Percy</li>
          <li>Testtool implementations, e.g. Playwright</li>
        </ul>
      </p>
      <br/>
      <h4>Pros:</h4>
      <ul>
        <li><strong>Easy</strong>&nbsp;A lot of tools who support visual testing are easy to implement and use</li>
        <li><strong>Visual regression</strong>&nbsp;By using tools you can monitor visual regression more easily than by doing it manually</li>
      </ul>
      <br/>
      <h4>Cons:</h4>
      <ul>
        <li><strong>Flaky</strong>&nbsp;Visual comparisons can result in flaky tests if thresholds are not correctly setup</li>
        <li><strong>Pricing</strong>&nbsp;Good tools are paid and doing a lot of comparisons could increase the licensing costs a lot</li>
      </ul>
      <br/>
      <h4>Conclusion</h4>
      <p>
        If you are using visual regression testing (tools) in your current setup, please continue doing so. But keep in mind the size of your
        visual test set and keep looking at maintainability and usage.
        We expect in the future that AI will contribute to visual regression testing by making it easier to compare snapshots and update baselines,
        so we will keep an eye on that.
      </p>
    `
  },
  {
    name: "PBT (property-based testing)",
    ring: "Trial",
    quadrant: "Techniques",
    isNew: "FALSE",
    status: "No Change",
    description: `
      <h4>Description</h4>
      <p>
        Property-based testing is a powerful testing methodology that allows developers to automatically generate and test a wide range of input data against
        specified properties of the software under test. Unlike traditional example-based testing, which uses specific, predefined inputs, property based
        testing explores the entire input space to uncover edge cases and potential bugs.
      </p>
      <br/>
      <p>
        Examples of frameworks
        <ul>
          <li>QuickCheck</li>
          <li>Hypothesis</li>
          <li>ScalaCheck</li>
        </ul>
      </p>
      <br/>
      <h4>Pros:</h4>
      <ul>
        <li><i>unknown</i></li>
      </ul>
      <br/>
      <h4>Cons:</h4>
      <ul>
        <li><i>unknown</i></li>
      </ul>
      <br/>
      <h4>Conclusion</h4>
      <p>
        Property-based testing is a robust and versatile testing methodology that complements traditional example-based testing.<br/>
        We would like to trial this technique and give a better judgment in a follow-up techradar.
      </p>
    `
  },
  {
    name: "Mutation testing",
    ring: "Hold",
    quadrant: "Techniques",
    isNew: "FALSE",
    status: "No Change",
    description: `
      <h4>Description</h4>
      <p>
        Mutation testing is conceptually quite simple.<br/>
        Faults (or mutations) are automatically seeded into your code, then your tests are run. If your tests fail then the mutation is killed, if your tests pass then the mutation lived.<br/>
        The quality of your tests can be gauged from the percentage of mutations killed.
      </p>
      <br/>
      <p>
        A short list of mutation testing tools (incomplete)
        <ul>
          <li>PIT (pitest.org)</li>
          <li>Arcmutate (arcmutate.com)</li>
          <li>Stryker Mutator (stryker-mutator.io)</li>
        </ul>
      </p>
      <br/>
      <h4>Pros:</h4>
      <ul>
        <li><strong>Detect faults</strong>&nbsp;Mutation testing can check if your (unit) tests actually detects faults</li>
      </ul>
      <br/>
      <h4>Cons:</h4>
      <ul>
        <li><i>none</i></li>
      </ul>
      <br/>
      <h4>Conclusion</h4>
      <p>
        Traditional test coverage (i.e line, statement, branch, etc.) measures only which code is executed by your tests.
        It does not check that your tests are actually able to detect faults in the executed code. It is therefore only able to identify code that is definitely not tested.<br/>
        Mutation testing is much better, as it is actually able to detect whether each statement is meaningfully tested. Therefore giving an accurate report on the quality of your tests.
      </p>
    `
  },
  {
    name: "Shift Left",
    ring: "Adopt",
    quadrant: "Techniques",
    isNew: "FALSE",
    status: "FALSE",
    description: `
      <h4>Description</h4>
      <p>
        Description
      </p>
      <br/>
      <h4>Pros:</h4>
      <ul><li><strong>pro</strong> description</li></ul>
      <br/>
      <h4>Cons:</h4>
      <ul><li><strong>con</strong> description</li></ul>
      <br/>
      <h4>Conclusion</h4>
      <p>This is the conclusion</p>
    `
  },
  {
    name: "Shift Right",
    ring: "Trial",
    quadrant: "Techniques",
    isNew: "FALSE",
    status: "FALSE",
    description: `
      <h4>Description</h4>
      <p>
        Description
      </p>
      <br/>
      <h4>Pros:</h4>
      <ul><li><strong>pro</strong> description</li></ul>
      <br/>
      <h4>Cons:</h4>
      <ul><li><strong>con</strong> description</li></ul>
      <br/>
      <h4>Conclusion</h4>
      <p>This is the conclusion</p>
    `
  },
  {
    name: "Component testing",
    ring: "Trial",
    quadrant: "Techniques",
    isNew: "FALSE",
    status: "FALSE",
    description: `
      <h4>Description</h4>
      <p>
        Description
      </p>
      <br/>
      <h4>Pros:</h4>
      <ul><li><strong>pro</strong> description</li></ul>
      <br/>
      <h4>Cons:</h4>
      <ul><li><strong>con</strong> description</li></ul>
      <br/>
      <h4>Conclusion</h4>
      <p>This is the conclusion</p>
    `
  },
]

exports.techniques = {
  content,
}
